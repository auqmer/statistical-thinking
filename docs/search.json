[
  {
    "objectID": "courses.html",
    "href": "courses.html",
    "title": "Courses",
    "section": "",
    "text": "Experimental Design (ERMA 7300)\n\nVisualizing and Describing Data\n\nExploring Data Graphically - Tutorial Video\nMeasures of Central Tendency - Tutorial Video\nMeasures of Variability - Tutorial Video\n\n\n\n\nLinear Modeling (ERMA 7310)\n\nFoundations of Modeling\n\nIntroduction to R and RStudio - Video\nFile Folders and Navigation Video\n\n\n\n\nStructural Equation Modeling (ERMA 8340)\n\nFoundations of Structural Equation Modeling\n\nIntroduction to Structural Equation Modeling\nRegression Fundamentals\n\nPreparing SPSS data for Mplus - Tutorial\nPreparing R data for Mplus - Video\n\nModeling and Hypothesis Testing\n\nHypothesis Testing Video\nBootstrapping Video\n\nModel Specification - Path Analysis\n\nPath Specification Video\nPath Identification Video\nUsing Mplus Diagrammer Video\nUsing Onyx to diagram Video\n\nGraph Theory\n\nDAG Basics Video\nDiagramming Causal Graphs Video\n\nThinking Clearly Video\n\nModel Specification - CFA Video\nModel Specification - SEM\n\nSpecification Video\nDemonstration Video\n\nModel Analysis - Local Fit\n\nEstimation Methods Video\nStandardization and Path Analysis Video\n\nModel Analysis - Global Fit\n\nGlobal Fit Theory Video\nGlobal Fit Demonstration Video\n\nModel Analysis - CFA\n\nCFA Analysis Video\nCFA Analysis Demonstration Video\n\nModel Analysis - SEM Video\n\n\n\n\nMultilevel Modeling (ERMA Special Topics)\n\n\nAdvanced Psychometrics (ERMA 8350)"
  },
  {
    "objectID": "methodsoverview.html#quantitative-methods",
    "href": "methodsoverview.html#quantitative-methods",
    "title": "Overview of Research Methods",
    "section": "Quantitative Methods",
    "text": "Quantitative Methods"
  },
  {
    "objectID": "methodsoverview.html#qualitative-methods",
    "href": "methodsoverview.html#qualitative-methods",
    "title": "Overview of Research Methods",
    "section": "Qualitative Methods",
    "text": "Qualitative Methods"
  },
  {
    "objectID": "methodsoverview.html#action-research",
    "href": "methodsoverview.html#action-research",
    "title": "Overview of Research Methods",
    "section": "Action Research",
    "text": "Action Research"
  },
  {
    "objectID": "notebooks.html",
    "href": "notebooks.html",
    "title": "Notebooks",
    "section": "",
    "text": "These notebooks are under construction.\nRegression Modeling: A Computational Project-Based Approach\nAdvanced Measurement Theory: A Computational Project-Based Approach"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistical Thinking",
    "section": "",
    "text": "This website contains resources relevant to research design and analysis applied social and behavioral sciences. While basic courses in statistics are essential to most graduate programs, they generally are not sufficient to prepare researchers to advance modern fields of inquiry, particularly on the cutting edge of modern empirical work. This site provides resources that not only build upon a researcher’s basic understanding of quantitative methods, but also provide access to such information after completing graduate course work.\nThe menu at the left of the pages will allow you to navigate through the topics. There is also a search option which can be used by clicking the magnifying glass in the top right of the site. The navigation bar at the top of the page has additional links that may be useful.\nI hope you find the content useful!\n\nContact\n\nMaintained by:\nWilliam M. Murrah, Ph.D.\nAssociate Professor,\nCollege of Education, Auburn University"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "Dr. William (Hank) Murrah, Ph.D.\nAs an educational researcher, I focus on understanding how people learn to think. My work falls into three main areas: (1) studying the skills children need to succeed in school; (2) developing interventions that address resource disparities important for learning; (3) developing methods to understand the impact of social and contextual factors on learning, motivation, and achievement. I am co-founder of the Quantitative Methods in Educational Research learning community, which is dedicated to supporting the growth and development of graduate students. A major goal of his when working with graduate students is to provide experiences with empirical research that helps them to stand out as scholars by providing skills needed to succeed as modern educational researchers."
  },
  {
    "objectID": "software.html",
    "href": "software.html",
    "title": "Software for Research",
    "section": "",
    "text": "Introduction to R and RStudio"
  },
  {
    "objectID": "introR.html",
    "href": "introR.html",
    "title": "Introduction to R and RStudio",
    "section": "",
    "text": "Statistical Programs\n\nfixed menus\nlimited procedures (at least in the menus)\nleads to compartmentalizing models (e.g. ANOVA, regression, GLM)\n\nStatistical Programming Languages (SPLs)\n\nTuring complete: if you can create an algorithm you can program it\nVery flexible\nIntegration of models: One model to rule them all!\n\n\nR is a statistical programming language, which means it is a programming language designed specifically to do statistics."
  },
  {
    "objectID": "introR.html#installing-r-and-rstudio",
    "href": "introR.html#installing-r-and-rstudio",
    "title": "Introduction to R and RStudio",
    "section": "Installing R and RStudio",
    "text": "Installing R and RStudio\nThe goal of this chapter is to get you up and running with the R statistical programming language and the RStudio integrated development environment.\nIf you are reading this because you are taking one of my courses, you must decide how you want to use R and RStudio for the course. You have two basic options:\n\nyou can install them on your own computer, or\nyou can use Auburn Universities education virtual lab (VLab), online.\n\nIf you have a computer that you will be using consistently for this course, I recommend installing R and RStudio on that computer. Both are free and will be much easier to use if you install them directly on your computer. If you have decided to install the software on your computer you can skip to the following video. Note, that you must be a student within the university, and have DUO setup to use VLab. If you think you want to use the virtual lab, watch this video:\nUsing VLab to acces R/RStudio\n\nInstalling R\nTo install R go to www.cran.r-project.org, select the appropriate operating system and follow the instructions to install R. You must have R install to use RStudio, so do this first.\nHere is a video demonstrating the installation of R:\nInstall R\n\n\nInstalling RStudio\nTo install RStudio go to www.posit.co and follow the links to download the free desktop version of RStudio.\nHere is a video demonstrating the installation of Rstudio:\nInstall RStudio"
  },
  {
    "objectID": "introR.html#r-as-a-statistical-programming-language",
    "href": "introR.html#r-as-a-statistical-programming-language",
    "title": "Introduction to R and RStudio",
    "section": "R as a Statistical Programming Language",
    "text": "R as a Statistical Programming Language\nTo help you understand R I describe some basic concepts important to understanding R as a statistical programming language (SPL). Such concepts will hopefully help you organize what you are learning. This is important because you will not be able to memorize all of the things you need to do to use R. But, having some general concepts should help you build a solid foundation of skills. This explanation will be a gross oversimplification of R, but it should be a good starting model you can build later.\n\n\n\n\nElements of Statistical Programming\nAn object is a thing that has one or more states, and one or more behaviors. Take for example you cell phone. It has many states, such as on or off, and many behaviors, such as making phone calls, sending texts, or surfing the web. Everything in R is an object. Objects in R are very similar to objects like your cell phone, in that they have states and behaviors. Our goal is to learn how to use these objects to help us do science.\nThere are basically two types of objects in R: data objects and function objects. Data objects store information, while function objects process or manipulate information.\n\nExpressions\nWe use objects in R through expressions. An expression is simply a combination of objects that R can evaluate. So, we type something into R, R processes it and gives us the results. For example, if we type 1 + 2 into the R console, it will give us the result 3:\n\n1 + 2\n\n[1] 3\n\n\nSo, expressions are simply objects or combinations of objects submitted to R in a way R can evaluate them.\n\n\nBasic Elements of a Good SPL\n\na rich set of primitive expressions\nmechanisms for combining expressions into more complex expressions\nmeans of abstraction, which allow for naming and manipulating compound objects\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrimitive Expressions\n\nEverything in R is an object\nPrimitive objects are the simplest elements of a programming language, and include:\n\nprimitive data\nprimitive functions\n\nThey can be thought of as the basic building blocks for everything else in the language.\nAn expression is an input that the programming language can evaluate, and consists of function and data objects.\n\n\n\nPrimitive Data Types:\nData objects are the primary means of storing information in R. R has a few basic data types:\n\nNumeric -\n\nnumeric\n\nint - integers (1,2)\nnum - real number (1.2, -3.1, 200.0)\n\n\ncharacter or string -\n\ncharacter\n\n\"Hello world!\", \"Ten\", 'Cat'\n\"This is a sentence, which is a string\"\n\"10\" ( in single or double quotes, as long as they match)\n\n\nBoolean or Logical\n\nlogical\n\nTRUE or FALSE (use operators such as or, and and not).\nThey will evaluate to numbers where FALSE evaluates to zero, and TRUE evaluates to one.\nFor example. if you enter TRUE + 1 you will get 2 in return.\n\n\n\n\nmode(TRUE)\n\n[1] \"logical\"\n\nTRUE + 1\n\n[1] 2\n\n\n\n\nPrimitive Functions\nR uses functions to do all computations.\n\nOperators\n\nArithmetic Operators\n\n+, -, *, /, ^\n\nComparison (also called Boolean, Logical or Predicate) Operators\n\n<,>,==, <=, >=, !=\nless than, greater than, equal to, less than or equal to, greater than or equal to, not equal to\nreturn TRUE or FALSE\n\nLogical Operator\n\n&, | ,!\nalso return TRUE or FALSE\n\nOther functions\n\nmode()\nlength()\nsum()\nsqrt()\nlog()\nexp()\n\nAssignment operators (assignment will be discussed below)\n\n<- preferred assignment operator - always use this one\n= this will also work, but can be confusing (note different from ==, the comparison operator)\n-> is also an assignment operator, but we will not use it.\n\n\n\n\n\nProgramming Languages are Not Forgiving\n\nSyntactically valid expressions\nExpressions must be syntactically valid.\n\nsyntax (form)\n\nEnglish: “cat dog boy” - not syntactically valid\nEnglish: “cat hugs boy” - syntactically valid\n\nprogramming language:\n\n“hi” 5 - not syntactically valid\n3.2*5 - syntactically valid\n\n\n\n\nSemantically valid expressions\n\nsemantics - (meaning)\n\nEnglish: “I are hungry” - syntactically valid but semantic error\nprogramming language:\n\n3 + “hi” - semantic error (you can’t use addition on character strings)\n\n\nChomsky: “colorless green ideas sleep furiously”\n\nThis statement is syntactically valid, but does not make sense, so makes a semantic error.\nIn R you have to combine expressions in a way that R “understands” and this combination should be meaningful.\n\n\n\nAssignment\nWe will often want to save data in a variable. We can do that with assignment, which utilizes an assignment operator.\n\nx <- 2\n\n\nx\n\n[1] 2\n\n\n\npet <- \"dog\"\n\n\npet\n\n[1] \"dog\"\n\n\nAssignments are special expressions that are composed of three parts, a name, an assignment operator, and an expression.\nFor the following assignment,\n\nx <- 1:10\n\nx is the name, <- is the assignment operator, and 1:10 is an expression. Names in R can be anything that includes letters, numbers, a period (.) or an underscore (_), as long as it begins with either a letter or a period. Here are some valid, followed by invalid names\n\n# Valid\nIQ\nc3p0\nHeight_inches\nweight.lbs\n.hidden\n\n# Invalid (you will get an error message)\n_cat\n1dog\n%sales\nHeigth-Inches\n\nThere are also some names that cannot be used because they are names of primitive R objects (e.g. if, for, else, in). Type ?reserved in the R console for a complete list.\nThere are at least three assignment operators, as mentioned above, but it is commonly recommended that you use <-, because it makes clear that you are taking some expression and putting it in an object. So we would say of the assignment of x <- 1:10 that x gets the integers 1 through 10, suggesting that we are putting the integers into the object x.\nJust about any expression can be passed to a name with the assignment operator.\n\n\nCombining Expressions\n\n\n\n\n\n\n\nComplex Data Types\n\nScalars, Vectors, Matrices, and Arrays\nLists\nDataframes\n\n\n\nGrouping Homogeneous Data Types\n\ncombining scalars\n\nc()\n\ncombining expressions\n\n{}\n\ncombining vectors\n\ncbind()\nrbind()\n\n\nComplex Functions\n\nVectorization\nNested Functions\nLoops and Conditional execution\n\n\n\nAbstraction\n\nAssignment\n\n\n\n\nData Abstraction\n\n\nFunctional Abstraction\n\n\nAnatomy of a Function\nname <- function(arg_1, arg_2, ...) {\n    expression_1\n    expression_2\n    ...\n    output <- expression_3\n    return(output)\n}"
  },
  {
    "objectID": "nonexperimental.html",
    "href": "nonexperimental.html",
    "title": "Non-Experimental Design and Analysis",
    "section": "",
    "text": "Summer 2021 Regression in R\nHere I have linked to recordings of our Summer 2021 RuseR Group for linear models in R. They are raw, unedited versions. The goal of the meetings was to give students who either were learning or had learned to do regression in other software the skills to so do in R.\nFriday June 6, 2021 - Introduction\nFriday June 9, 2021 - Simple and Multiple Regression\nFriday June 16, 2021 - Interpreting Categorical Variables\nFriday July 23, 2021 - Interactions"
  },
  {
    "objectID": "fiml.html",
    "href": "fiml.html",
    "title": "Full Information Maximum Likelihood",
    "section": "",
    "text": "Full information maximum likelihood (FIML) is a modern statistical technique for handling missing data. If you are not familiar with FIML, I would recommend the book entitled Applied Missing Data Analysis by Craig Enders. The book is both thorough and accessible, and a good place to start for those not familiar with the ins and outs of modern missing data techniques.\nThe purpose of this FIML in Lavaan section and the related git repository is to take some of the examples related to FIML estimation within a regression framework from the Applied Missing Data website, and translate them into code for the R package lavaan. The code on the Applied Missing Data website in mostly for Mplus, which is quite expensive software. I hope this will give those who don’t have access to Mplus the ability to work through the examples using free and open source software.\nIn this first subsection I start with the basics: how to get descriptive statistics using FIML. The data and Mplus code for this example can be found on the Book Examples page of the Applied Missing Data website. I also created a github repository with the data and R files with equivalent code in lavaan, which can be found here. Remember to replace the file path in the R code below with the file path to the folder in which you unzip the data files.\nYou will also want to read over the lavaan documentation and visit the very helpful lavaan website to take advantage of the tutorials there. With these resources at your disposal, you should be able to use replicate the examples in lavaan. Here, I walk through the major sections of the R code. This is the same code found in the github repository in the R file entitled FIMLdescriptivesCorrelations.R.\n\n\nI always include a header with basic information in my code files.\n\n#-----------------------------------------------------------------------\n# section 4.14 Summary Statistics \n# Author: William M. Murrah\n# Description: This code replicates the section 4.14 example on the \n#              the appliedmissingdata.com website, which generates \n#              descriptive statistics and correlations,\n# Version history ------------------------------------------------------\n# 2014.05.30: code created\n# 2014.06.01: rewrote heading\n#-----------------------------------------------------------------------\n# R packages used\nlibrary(lavaan)\n\n\n\n\nFirst, import the data into R. MPlus uses .dat files which can only contain numbers. Variable names are not included in the .dat file, but instead are included in the Mplus .inp file. I use the read.table function to read the .dat file.\n\n    employee <- read.table(\"data/employee.dat\")\n\nNext, I assign names to the variables in the new data frame.\n\n    # Assign names to variables.\n    names(employee) <- c(\"id\", \"age\", \"tenure\", \"female\", \"wbeing\", \n                         \"jobsat\", \"jobperf\", \"turnover\", \"iq\")\n\nThe final step in preparing the data is to recode the data values -99, which are used as missing data values in the .dat file, to NA, which is the missing value indicator in R.\n\n    # Replace all missing values (-99) with R missing value character 'NA'.\n    employee[employee==-99] <- NA\n\n\n\n\nNow that the data are ready, I create a character string with the model using the lavaan syntax. For descriptives and correlations I model the mean, variances, and covariance/correlations.\n\n    # Create descriptive model object\n    model <- '\n    # means\n    age      ~ 1\n    tenure   ~ 1\n    female   ~ 1\n    wbeing   ~ 1\n    jobsat   ~ 1\n    jobperf  ~ 1\n    turnover ~ 1\n    iq       ~ 1\n    \n    # variances\n    age      ~~ age\n    tenure   ~~ tenure\n    female   ~~ female\n    wbeing   ~~ wbeing\n    jobsat   ~~ jobsat\n    jobperf  ~~ jobperf\n    turnover ~~ turnover\n    iq       ~~ iq\n    \n    # covariances/correlations\n    age      ~~ tenure + female + wbeing + jobsat + jobperf + turnover + iq\n    tenure   ~~ female + wbeing + jobsat + jobperf + turnover + iq\n    female   ~~ wbeing + jobsat + jobperf + turnover + iq\n    wbeing   ~~ jobsat + jobperf + turnover + iq\n    jobsat   ~~ jobperf + turnover + iq\n    jobperf  ~~ turnover + iq\n    turnover ~~ iq\n    '\n\n\n\n\nTo fit the model, I use the lavaan sem function. This function takes the first two argument model and data. The third argument is missing ='fiml', which tells lavaan to use FIML (the default is to use listwise deletion).\n\n    fit <- sem(model, employee, missing='fiml')\n\nAlternatively, you could leave the section of the model code under the # means section and use the meanstructure=TRUE argument in the fit function as follows, which give the same results:\n\n    fit <- sem(model, employee, missing='fiml', meanstructure=TRUE)\n\n\n\n\nTo print the results to the console, use the summary function.\n\n    summary(fit, fit.measures=TRUE, standardize=TRUE)\n\nThe fit.measures=TRUE calls fit statistics in the output. This should look familiar to those who have used Mplus.\nlavaan (0.5-16) converged normally after 141 iterations\n\n  Number of observations                           480\n\n  Number of missing patterns                         3\n\n  Estimator                                         ML\n  Minimum Function Test Statistic                0.000\n  Degrees of freedom                                 0\n  P-value (Chi-square)                           1.000\n\nModel test baseline model:\n\n  Minimum Function Test Statistic              527.884\n  Degrees of freedom                                28\n  P-value                                        0.000\n\nUser model versus baseline model:\n\n  Comparative Fit Index (CFI)                    1.000\n  Tucker-Lewis Index (TLI)                       1.000\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -6621.805\n  Loglikelihood unrestricted model (H1)      -6621.805\n\n  Number of free parameters                         44\n  Akaike (AIC)                               13331.609\n  Bayesian (BIC)                             13515.256\n  Sample-size adjusted Bayesian (BIC)        13375.604\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.000\n  90 Percent Confidence Interval          0.000  0.000\n  P-value RMSEA <= 0.05                          1.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.000\nThe standardize=TRUE argument includes columns with standardized output. the std.all column in lavaan output is the same as the STDYX section in Mplus.\nParameter estimates:\n\n  Information                                 Observed\n  Standard Errors                             Standard\n\n                   Estimate  Std.err  Z-value  P(>|z|)   Std.lv  Std.all\nCovariances:\n  age ~~\n    tenure            8.459    0.858    9.865    0.000    8.459    0.504\n    female           -0.028    0.122   -0.229    0.819   -0.028   -0.010\n    wbeing            1.148    0.334    3.433    0.001    1.148    0.182\n    jobsat            0.861    0.340    2.531    0.011    0.861    0.136\n    jobperf          -0.330    0.308   -1.072    0.284   -0.330   -0.049\n    turnover         -0.377    0.116   -3.255    0.001   -0.377   -0.150\n    iq                0.674    2.066    0.326    0.744    0.674    0.015\n  tenure ~~\n    female           -0.052    0.071   -0.736    0.462   -0.052   -0.034\n    wbeing            0.569    0.195    2.916    0.004    0.569    0.155\n    jobsat            0.565    0.200    2.822    0.005    0.565    0.154\n    jobperf           0.061    0.178    0.344    0.731    0.061    0.016\n    turnover          0.016    0.066    0.240    0.810    0.016    0.011\n    iq                0.026    1.199    0.022    0.983    0.026    0.001\n  female ~~\n    wbeing            0.067    0.031    2.156    0.031    0.067    0.115\n    jobsat            0.028    0.031    0.881    0.378    0.028    0.047\n    jobperf          -0.009    0.029   -0.323    0.747   -0.009   -0.015\n    turnover          0.001    0.011    0.114    0.909    0.001    0.005\n    iq                0.284    0.192    1.481    0.139    0.284    0.068\n  wbeing ~~\n    jobsat            0.446    0.095    4.714    0.000    0.446    0.322\n    jobperf           0.671    0.084    8.030    0.000    0.671    0.456\n    turnover         -0.141    0.030   -4.768    0.000   -0.141   -0.257\n    iq                2.876    0.530    5.430    0.000    2.876    0.291\n  jobsat ~~\n    jobperf           0.271    0.080    3.378    0.001    0.271    0.184\n    turnover         -0.129    0.030   -4.248    0.000   -0.129   -0.234\n    iq                4.074    0.566    7.195    0.000    4.074    0.411\n  jobperf ~~\n    turnover         -0.203    0.028   -7.168    0.000   -0.203   -0.346\n    iq                4.496    0.523    8.588    0.000    4.496    0.426\n  turnover ~~\n    iq               -0.706    0.182   -3.872    0.000   -0.706   -0.180\n\nIntercepts:\n    age              37.948    0.245  154.633    0.000   37.948    7.058\n    tenure           10.054    0.142   70.601    0.000   10.054    3.222\n    female            0.542    0.023   23.817    0.000    0.542    1.087\n    wbeing            6.288    0.062  100.701    0.000    6.288    5.349\n    jobsat            5.950    0.063   94.052    0.000    5.950    5.053\n    jobperf           6.021    0.057  105.262    0.000    6.021    4.805\n    turnover          0.321    0.021   15.058    0.000    0.321    0.687\n    iq              100.102    0.384  260.475    0.000  100.102   11.889\n\nVariances:\n    age              28.908    1.866                     28.908    1.000\n    tenure            9.735    0.628                      9.735    1.000\n    female            0.248    0.016                      0.248    1.000\n    wbeing            1.382    0.107                      1.382    1.000\n    jobsat            1.386    0.108                      1.386    1.000\n    jobperf           1.570    0.101                      1.570    1.000\n    turnover          0.218    0.014                      0.218    1.000\n    iq               70.892    4.576                     70.892    1.000\nRecall that correlations are standardized covariances, so correlations are found in the std.all column in the Covariances section. Also, intercepts are means, and can be interpreted as the FIML means for the variables.\nFinally, to get the missing data patterns and covariance coverage output that can be included in Mplus output use the following code:\n\n    # Get missing data patterns and covariance coverage similar\n    # to that found in Mplus output.\n    inspect(fit, 'patterns') \n    inspect(fit, 'coverage')\n\nwhich leads to the following output:\n\n\n    age tenure female wbeing jobsat jobprf turnvr iq\n160   1      1      1      1      1      1      1  1\n160   1      1      1      1      0      1      1  1\n160   1      1      1      0      1      1      1  1\n\n\n\n\n         age   tenure female wbeing jobsat jobprf turnvr iq   \nage      1.000                                                \ntenure   1.000 1.000                                          \nfemale   1.000 1.000  1.000                                   \nwbeing   0.667 0.667  0.667  0.667                            \njobsat   0.667 0.667  0.667  0.333  0.667                     \njobperf  1.000 1.000  1.000  0.667  0.667  1.000              \nturnover 1.000 1.000  1.000  0.667  0.667  1.000  1.000       \niq       1.000 1.000  1.000  0.667  0.667  1.000  1.000  1.000\n\n\n\n\n\n\n\nIn this subsection I use FIML to deal with missing data in a multiple regression framework. First, I import the data from a text file named ‘employee.dat’. You can download a zip file of the data from Applied Missing Data website. I also have a github page for these examples here. Remember to replace the file path in the read.table function with the path to the text file location on your computer.\n\nemployee <- read.table(\"data/employee.dat\")\n\nBecause the original text file does not include variable names, I name the variables in the new data frame:\n\nnames(employee) <-  c(\"id\", \"age\", \"tenure\", \"female\", \"wbeing\", \"jobsat\", \n                     \"jobperf\", \"turnover\", \"iq\")\n\nthen I recode all data points with the value of -99 in the original text file, which indicates a missing value, to NA, the missing data value recognized by R.\n\nemployee[employee == -99] <-  NA\n\n\n\n\nNow we are ready to create a character string containing the regression model using the lavaan model conventions. Note that b1 and b2 are labels that will be used later for the Wald test. These labels are equivalent to (b1) and (b2) after these variables in the Mplus code.\n\nmodel <- '\n# Regression model \njobperf ~ b1*wbeing + b2*jobsat\n\n# Variances\nwbeing ~~ wbeing\njobsat ~~ jobsat\n\n# Covariance/correlation\nwbeing ~~ jobsat\n'\n\nIn addition to the regression model, I also estimated the variances and covariances of the predictors. I did this to replicate the results of the original Mplus example. In Mplus you have to estimate the variances of all of the predictors if any of them have missing data that you would like to model. In lavaan the fixed.x=FALSE argument has the same effect (see below).\n\n\n\nNext, I use the sem function to fit the model.\n\nfit <- sem(model, employee, missing='fiml', meanstructure=TRUE, \n           fixed.x=FALSE)\n\nListwise deletion is the default, so the missing=‘fiml’ argument tell lavaan to use the FIML instead. I also included the meanstructure=TRUE argument to include the means of the observed variables in the model, and the fixed.x=FALSE argument to estimate the means, variances, and covariances. Again, I do this to replicate the results of the original Mplus example.\n\n\n\nWe are now ready to look at the results.\n\nsummary(fit, fit.measures=TRUE, rsquare=TRUE, standardize=TRUE)\n\nCompared to what we learned in the last section, the only thing new to the summary function is the rsquare=TRUE argument, which, not surprisingly, results in the model R2 being included in the summary output.\nI only show the Parameter estimates section here:\nParameter estimates:\n\n  Information                                 Observed\n  Standard Errors                             Standard\n\n                   Estimate  Std.err  Z-value  P(&gt;|z|)   Std.lv  Std.all\nRegressions:\n  jobperf ~\n    wbeing   (b1)     0.476    0.055    8.665    0.000    0.476    0.447\n    jobsat   (b2)     0.027    0.060    0.444    0.657    0.027    0.025\n\nCovariances:\n  wbeing ~~\n    jobsat            0.467    0.098    4.780    0.000    0.467    0.336\n\nIntercepts:\n    jobperf           2.869    0.382    7.518    0.000    2.869    2.289\n    wbeing            6.286    0.063   99.692    0.000    6.286    5.338\n    jobsat            5.959    0.065   91.836    0.000    5.959    5.055\n\nVariances:\n    wbeing            1.387    0.108                      1.387    1.000\n    jobsat            1.390    0.109                      1.390    1.000\n    jobperf           1.243    0.087                      1.243    0.792\n\nR-Square:\n\n    jobperf           0.208\n\n\n\nIn lavaan the Wald test is called separately from the estimation function. This function will use the labels assigned in the model object above.\n\n# Wald test is called seperately.\nlavTestWald(fit,  constraints='b1 == 0\n                               b2 == 0')\n\nResults of Wald Test\n$stat\n[1] 95.88081\n\n$df\n[1] 2\n\n$p.value\n[1] 0\nThere you have it! Regression with FIML in R. But, what if you have variables that you are not interested in incorporating in your model, but may have information about the missingness in the variables that are in your model? I will talk about that in the next subsection.\n\n\n\n\nNext I demonstrate two methods of using auxiliary variable in a regression model with FIML. Again, I am using data and examples from Craig Ender’s website Applied Missing Data. The purpose of these sections is to make the examples on Craig’s website, which uses Mplus, available to those who prefer to use lavaan\nMplus allows you to use auxiliary variable when using FIML to include variables that help estimate missing values with variables that are not part of the analytic model. There may be variables that are correlated with variables with missing values or variables that are predictive of missing. However, these auxiliary variable are not part of the model you wish to estimate. See Craig’s book Applied Missing Data Analysis for more information about auxiliary variables.\nI attended a workshop where Craig showed us how to use the auxiliary command in Mplus to make use of auxiliary variables. However, lavaan does not have this option. He also showed us what he called a ‘brute force’ method to include auxiliary variables in Mplus. Here is how to do it in lavaan.\n\n\nThis model is the same as used in my last section, where job performance (jobperf) is regressed on wellbeing (wbeing) and job satisfaction (jobsat). In this example these three variables are the only ones which we want to model. However, tenure and IQ are related to missingness in these variables. So, we want to use them to help us better estimate our model of interest. If we included them as predictors in the regression model, it would allow us to use all the available information in these five variables, but it would change the model substantially. We can use auxiliary variables to better estimate the original model.\n\n\nFirst we import data, name the variables, and recode the -99’s to NA.\n\n# employeeAuxiliary.R ---------------------------------------------------\n\n# R packages used\nlibrary(lavaan)\n# Import text file into R as a data frame.\n\nemployee <- read.table(\"path/to/file/employee.dat\")\n\n# Assign names to variables.\n\nnames(employee) <- c(\"id\", \"age\", \"tenure\", \"female\", \"wbeing\", \"jobsat\", \n                 \"jobperf\", \"turnover\", \"iq\")\n\n# Replace all missing values (-99) with R missing value character 'NA'.\nemployee[employee==-99] <- NA\n\n\n\n\nBasically, the brute force method entails correlating the auxiliary variables with other auxiliary variable, the predictors, and the residuals for the outcome variable.\n\n# The b1* and b2* are labels used in the Wald test below\nmodel <- '\njobperf ~ b1*wbeing + b2*jobsat\nwbeing ~~ jobsat\nwbeing ~~ turnover + iq\njobsat ~~ turnover + iq\njobperf ~~ turnover + iq\nturnover ~~ iq\n'\n\n\n\n\n\nfit <- sem(model, employee, missing='fiml', fixed.x=FALSE, \n           meanstructure=TRUE)\nsummary(fit, fit.measures=TRUE, rsquare=T, standardize=T)\n\n\n\n\nJust as we did in the previous section.\n\nlavTestWald(fit, \n            'b1 == 0\n             b2 == 0')\n\n\n\n\n\nFirst, load the semTools package\n\nlibrary(semTools)\n\n\n\nNext, create a model object with just the model of interest\n\nmodel2 <- '\njobperf ~ wbeing + jobsat\n'\n\nThen, create a vector of the names of the auxiliary variables\n\naux.vars <- c('turnover', 'iq')\n\n\n\n\nThen, fit the model to the new model object.\n\nfit2 <- sem(model2, employee, missing='fiml', meanstructure=TRUE, fixed.x=FALSE)\n\nUsing this model object, fit another model that incorporates the auxiliary variables using the sem.auxiliary function from the semTools package.\n\nauxfit <- sem.auxiliary(model=fit2, aux=aux.vars, data=employee)\n\nFinally, summarize the model object that includes the auxiliary variables.\n\nsummary(auxfit, fit.measures=TRUE, rsquare=TRUE, standardize=TRUE)"
  }
]