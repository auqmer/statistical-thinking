[
  {
    "path": "posts/2020-09-08-exploring-data-graphically/",
    "title": "Exploring Data Graphically",
    "description": "Before we start simplifying our data with descriptive statistics and then models, we should always explore all the data. A great way to do that is graphically.",
    "author": [
      {
        "name": "William Murrah",
        "url": "www.statistical-thinking.com"
      }
    ],
    "date": "2020-09-08",
    "categories": [],
    "contents": "\n\n\nlibrary(mosaic)\n\n\n\nBefore you start simplifying your data with descriptive statistics, it is essential that you explore all your data. A reasoned use of graphics is indispensable for this purpose. In this tutorial, I will demonstrate some of the most commonly used graphical methods to explore experimental data.\nR has extensive methods for graphics, which allow for amazing visualizations of data. My purpose here is to teach you the basics of graphics, so I will stick with some relatively simple graphics in base R.\nBar Graphs\nTypically, the type of graph you use depends on the type of data you are exploring.\nWe will use the mtcars data, which is part of base R. Below, I load the data, then transform two variables to factors, which is how R handles categorical variables. Take a look at the help file for mtcars by typing ?mtcars into the R console. Look at the data description under the “Format” heading to see how I decided to label the two factors vs and am. You should also read through this list of variable names and labels to understand what our data are measuring.\n\n\ndata(mtcars)\n\nmtcars <- transform(mtcars,\n                    vs = factor(vs, labels = c(\"v-shaped\", \"straight\")),\n                    am = factor(am, labels = c(\"automatic\", \"manual\")))\n\n\n\nWhen we have a categorical variable, we often want to know how many cases are in each category. In R a categorical variable is called a factor, and the categories within that variable are called levels. Let’s look at the vs factor, which describes the shape of the engine for each car. First, I will simply table this variable:\n\n\ntable(mtcars$vs)\n\n\n\nv-shaped straight \n      18       14 \n\nWe can see that we have 18 cars with a V-shaped engine and 14 with a straight engine. Next, I will use the table function to create a bar plot.\n\n\nbarplot(table(mtcars$vs))\n\n\n\n\nNote, that the bar plot needs tabled data, so the table() function is nested within the first argument to this plot.\n\n\ntab <- table(mtcars$vs, mtcars$am)\ncolnames(tab)\nbarplot(tab, beside = TRUE, legend.text = rownames(tab), \n        main = \"Comparing engine shape to transmission type\", )\n\n\n\nHistograms\nSimilar to the bar graph is the histogram. The major difference is that histograms are most often used with continuous variables, instead of categorical variable. While bar graphs have natural groupings (the categories or levels), continuous variables do not. So, to create a histogram a continuous variable is binned into groups and the frequencies of cases in the range of those groups is plotted with a bar.\n\n\nhist(mtcars$mpg)\n\n\n\n\nIt is very important to remember that when you create a histogram a decision is being make about how to bin the data. This can impact the shape of the distribution, and your interpretation. It is often a good idea to play around with this binning. To do that in the R hist() function you can use the breaks = argument. This allows you to set the number of bins. For example, compare the two histograms of mpg.\n\n\nhist(mtcars$mpg, breaks = 3, main = \"Histogram pf mpg with 3 breaks\")\n\n\n\nhist(mtcars$mpg, breaks = 13, main = \"Histogram of mpg with 13 breaks\")\n\n\n\n\nAlso note that I called for 13 bins, but was given less than that. So, the hist() function only takes this value as a suggestion. See ?hist for more information.\n\n\nplot(density(mtcars$mpg))\n\n\n\nBoxplots\nBoxplots or box and whisker plots, are also useful for exploring the distribution of continuous variables. These plots visualize the median, interquartile range, the full range, and look for extreme values.\n\n\nboxplot(mtcars$mpg)\n\n\n\n\n\n\n(qtle <- quantile(mtcars$mpg))\n\n\n    0%    25%    50%    75%   100% \n10.400 15.425 19.200 22.800 33.900 \n\nboxplot(mtcars$mpg, horizontal = TRUE)\ntext(x = qtle[1], y = 1.3, labels = paste(\"0%\\n\", qtle[1]))\ntext(x = qtle[2], y = 1.3, labels = paste(\"25%\\n\", qtle[2]))\ntext(x = qtle[3], y = 1.3, labels = paste(\"50%\\n\", qtle[3]))\ntext(x = qtle[4], y = 1.3, labels = paste(\"75%\\n\", qtle[4]))\ntext(x = qtle[5], y = 1.3, labels = paste(\"100%\\n\", qtle[5]))\n\n\n\nhist(mtcars$mpg)\n\n\n\n\n\n\nboxplot(mpg ~ vs, data = mtcars)\n\n\n\n\n\n\nboxplot(mpg ~ vs * am, data = mtcars, las = 3, ann = FALSE, xaxt = \"n\")\ntitle(ylab = \"Miles per Gallon\", \n      xlab = \"Engine Shape and Transmission Type\",\n      main = \"Miles per Gallon by Engine Shape and Transmission Type\")\naxis(side = 1, at = 1:4, mgp = c(1,2,0), \n     labels =c(\"V-shaped\\nAutomatic\", \"straight\\nAutomatic\", \n                                   \"V-shaped\\nManual\", \"straight\\nManual\"))\n\n\n\n\nScatterplots\nScatterplots are useful when we want to compare two numeric variables. For example, let’s look at the relation between miles per gallon and horsepower.\n\n\nplot(mpg ~ hp, data = mtcars)\n\n\n\n\nNote that each point on the plot represents a single car, and indicates it’s horsepower on the x axis and it’s miles per gallon on the y axis. For example, the car represented by the left most point has a hp of about 50 and a mpg of a little more than 30. We see a negative relation between these two variables, a car with more horsepower is likely to have a lower miles per gallon.\n\n\n\n",
    "preview": "posts/2020-09-08-exploring-data-graphically/distill-preview.png",
    "last_modified": "2021-01-11T12:46:09-06:00",
    "input_file": "exploring-data-graphically.utf8.md"
  },
  {
    "path": "posts/2018-12-15-fiml-regression-auxiliary/",
    "title": "FIML in Lavaan: Regression Analysis with Auxiliary Variables",
    "description": "This is the third tutorial in a series that demonstrates how to us full information maximum likelihood (FIML) estimation using the R package `lavaan`.",
    "author": [
      {
        "name": "William Murrah",
        "url": "www.statistical-thinking.com"
      }
    ],
    "date": "2019-04-17",
    "categories": [],
    "contents": "\nIn this post, I demonstrate two methods of using auxiliary variable in a regression model with FIML. I am using data and examples from Craig Ender’s website Applied Missing Data. The purpose of these posts is to make the examples on Craig’s website, which uses Mplus, available to those who prefer to use lavaan\nMplus allows you to use auxiliary variable when using FIML to include variables that help estimate missing values with variables that are not part of the analytic model. There may be variables that are correlated with variables with missing values or variables that are predictive of missing. However, these auxiliary variable are not part of the model you wish to estimate. See Craig’s book Applied Missing Data Analysis for more information about auxiliary variables.\nI attended a workshop where Craig showed us how to use the auxiliary command in Mplus to make use of auxiliary variables. However, lavaan does not have this option. He also showed us what he called a ‘brute force’ method to include auxiliary variables in Mplus. Here is how to do it in lavaan.\nBrute Force Method\nThis model is the same as used in my last post, where job performance (jobperf) is regressed on wellbeing (wbeing) and job satisfaction (jobsat). In this example these three variables are the only ones which we want to model. However, tenure and IQ are related to missingness in these variables. So, we want to use them to help us better estimate our model of interest. If we included them as predictors in the regression model, it would allow us to use all the available information in these five variables, but it would change the model substantially. We can use auxiliary variables to better estimate the original model.\nImport Data\nFirst we import data, name the variables, and recode the -99’s to NA.\n\n\n# employeeAuxiliary.R ---------------------------------------------------\n\n# R packages used\nlibrary(lavaan)\n# Import text file into R as a data frame.\n\nemployee <- read.table(\"path/to/file/employee.dat\")\n\n# Assign names to variables.\n\nnames(employee) <- c(\"id\", \"age\", \"tenure\", \"female\", \"wbeing\", \"jobsat\", \n                 \"jobperf\", \"turnover\", \"iq\")\n\n# Replace all missing values (-99) with R missing value character 'NA'.\nemployee[employee==-99] <- NA\n\n\n\nCreate Regression Model Object (Brute Force)\nBasically, the brute force method entails correlating the auxiliary variables with other auxiliary variable, the predictors, and the residuals for the outcome variable.\n\n\n# The b1* and b2* are labels used in the Wald test below\nmodel <- '\njobperf ~ b1*wbeing + b2*jobsat\nwbeing ~~ jobsat\nwbeing ~~ turnover + iq\njobsat ~~ turnover + iq\njobperf ~~ turnover + iq\nturnover ~~ iq\n'\n\n\n\nFit and Summarize the Model\n\n\nfit <- sem(model, employee, missing='fiml', fixed.x=FALSE, \n           meanstructure=TRUE)\nsummary(fit, fit.measures=TRUE, rsquare=T, standardize=T)\n\n\n\nWald test\nJust as we did in the previous post.\n\n\nlavTestWald(fit, \n            'b1 == 0\n             b2 == 0')\n\n\n\nUsing auxiliary Command in semTools\nFirst, load the semTools package\n\n\nlibrary(semTools)\n\n\n\nCreate Regression Model Object\nNext, create a model object with just the model of interest\n\n\nmodel2 <- '\njobperf ~ wbeing + jobsat\n'\n\n\n\nThen, create a vector of the names of the auxiliary variables\n\n\naux.vars <- c('turnover', 'iq')\n\n\n\nFit the Model\nThen, fit the model to the new model object.\n\n\nfit2 <- sem(model2, employee, missing='fiml', meanstructure=TRUE, fixed.x=FALSE)\n\n\n\nUsing this model object, fit another model that incorporates the auxiliary variables using the sem.auxiliary function from the semTools package.\n\n\nauxfit <- sem.auxiliary(model=fit2, aux=aux.vars, data=employee)\n\n\n\nFinally, summarize the model object that includes the auxiliary variables.\n\n\nsummary(auxfit, fit.measures=TRUE, rsquare=TRUE, standardize=TRUE)\n\n\n\nThere you have it! Two way to use auxiliary variables in a regression model using lavaan.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-01-11T11:51:05-06:00",
    "input_file": {}
  },
  {
    "path": "posts/2019-01-13-prepare-spss-data-for-mplus/",
    "title": "Prepare SPSS Data for Mplus",
    "description": "This tutorial demonstrates how to prepare data from SPSS for use with Mplus.",
    "author": [
      {
        "name": "William Murrah",
        "url": "www.statistical-thinking.com"
      }
    ],
    "date": "2019-01-13",
    "categories": [],
    "contents": "\nWhen I have to prepare data for Mplus, I use the MplusAutomation package in R. Its great! I import the SPSS data file into R with the foreign package. Then I use the prepareMplusData() function to create a .dat file for use in Mplus. This function also creates basic Mplus code that can pasted into Mplus or a text file used to prepare Mplus code files. MplusAutomation has many other great features and I highly recommend it for those who use Mplus and R.\nBut many of my colleagues don’t use R, and therefore this option is not feasible. Recently I gave an informal talk to some colleagues on how to get data from SPSS to Mplus, which I thought might be useful to others who needed to manually prepare SPSS data for Mplus. Here, I include the steps I recommended with links to an SPSS syntax example.\nBefore describing the steps, I think it is important to point out the major differences between an SPSS data file and an Mplus data file. SPSS data files include variable names, variable labels and other information. They also may contain different types of variables including numeric, string, and date variables. Mplus data files are simply a tab delimited numeric matrix. No variable names and only numbers as data points. Variable names are supplied in the Mplus code and are not in the data file.\nBasic Steps\nThe following 6 steps can be used to get SPSS data ready for Mplus:\nMake a copy of the SPSS data file\nRecode any non-numeric variables you want to include in the Mplus data file\nRename variables longer than 8 characters\nDeal with missingness values (if necessary)\nSave SPSS data file as a tab delimited file (.dat)\nCreate basic code for Mplus\nCheck descriptive statistics and missingness patterns\n1. Make a copy of the SPSS file\nThis step is pretty simple. It is a good idea to keep an original copy of your data file. That way you can always start over. I will be using an example data file that contains a subset of cases and variables from the STAR public access data set. This data can be found in the R package AER. If you have R you can use the following code to generate the data file:\n\n\n\nYou can also find of copy of the SPSS file on my github page for this tutorial here. .\n2. Recode any non-numeric variables\nMplus only handles numeric data. This does not mean you can’t have categorical variables in your analyses, but they have to be coded with numbers. For example, the variable ‘gender’ in the star data frame consists of two string values: “female” and “male”. We can recode these so females have a value of ‘0’ and males have a value of ‘1’. The following SPSS syntax does the trick:\n    RECODE \n    gender\n    ('female' = 0)\n    ('male' = 1)\n    (MISSING=SYSMIS)\n     into male.\n    EXECUTE.\nNotice that I also renamed the variable ‘male’ to indicate the category the variable identifies. If you run across a variable named ‘gender’ coded as ‘0’s and ’1’s, you don’t know which value signifies females and which males. By naming the binary variable ’male’, I am indicating that ’1’s are males, therefore the ’0’s must be females. This is just good data management.\n3. Rename variables longer than 8 characters\nMplus only recognizes the first 8 characters of variable names. If the first 8 characters of each of your variables are unique, you might be okay with Mplus truncating your variable names. But if you have variables in which the first 8 characters are not unique you can run into major problems. For example, if you had variables named ‘kindergartenMath’ and ‘kindergartenRead’, Mplus would treat them as having the same variable name. So don’t overlook this step!\nThe following SPSS code renames the long variables in the star data:\n    RENAME VARIABLES \n    (ChildIdentification = childId)\n    (readKindergarten = readk)\n    (mathKindergarten = mathk).\n4. Deal with missing values\nThere are two types of missing data possible in an SPSS data frame. System missing data is indicated by a period (‘.’). You can also designate any numeric value as a user missing value (e.g. -99). You don’t necessarily have to change these values to prepare your data for Mplus. But you must at least know which values indicate missingness for EACH variable. I also note that I have experienced some difficulty with the period (‘.’) value as a missing indicator when preparing SPSS data for Mplus. I usually recode all missing values to one numeric value (e.g. -99, or -999) that is not in the range of possible values for any of my data. Later you will have to tell Mplus what values indicate missing data for your variables. It is much easier if this value is one number, and it is the same for all variables. However, you may have good reason to have different missing values. Again, just know what your missingness indicators are.\n5. Create a tab delimited file\nNow that you have an SPSS file in order, you need to save it as a tab delimited file. To do this you just need to click on the ‘File’ option in the SPSS dataSet menu,and then click ‘Save As’. In the ‘Save as type:’ menu on the resulting tab, select ’tab delimited (*.dat)‘. MAKE SURE THE ’Write variable names to speadsheet’ BOX IS NOT CHECKED! Mplus data files should only contain numbers. You can also use the ’Variables…’ radio to select only the variables you need in Mplus. This is useful if you have non-numeric variables in the original data file that you don’t want to use and therefore don’t what to waste time transforming. Below is a snippet of SPSS syntax that resulted from the above procedure on the star data.\n    SAVE TRANSLATE OUTFILE='C:\\Dropbox\\3_Teaching\\SPSS2MplusDemo\\starMplus.dat'\n      /TYPE=TAB\n      /MAP\n      /REPLACE\n      /CELLS=VALUES.\n6. Create basic code for Mplus\nFinally, you will want to create a basic set of code for Mplus that will be the basis of all your analyses used in Mplus. I will mention three things you want to make sure get into your Mplus code accurately. First, you need to include the path to your tab delimited file in the DATA section of your Mplus code file. Second, you want to make sure you have the variable names correct. Remember that Mplus data files only contain the numeric data. Variable names are assigned to each column of the tab delimited file with the VARIABLE command in the Mplus code file. To keep you from having to type in all the variable names, you can copy the column of variable names from the SPSS file (in Variable View) and paste them into EXCEL. Then use the transpose function in the ‘paste special’ menu to convert the column of names into a row of names. Then paste this row in the Mplus code file. Third, you need to tell Mplus what the missing data values are. Because I used -99 for the only missing value for ALL of my variables, the following code should be in the VARIABLE section of your Mplus code file:\n    MISSING ARE ALL (-99);\nI will mention one final peculiarity of Mplus that can trip up this process. Mplus only allows 80 characters on each line of code. So you may have to break up long rows into shorter rows. For example the file path and variable names often have to be broken up this way. If you don’t Mplus will give you an error message. If the data file (starMplus.dat) is in the same folder as the Mplus code file (let’s say we call it starBasic.inp) then the code file might look like this:\nTITLE:  STAR analysis\n\nDATA:\n  FILE IS \"starMplus.dat\";\n\nVARIABLE:\n  NAMES ARE childId readk   read1   mathk   math1\n  male  white other;\n  USEVARIABLES ARE readk-other;\n  MISSING ARE ALL (-99);\n  categorical are male-other;\nANALYSIS:\n  TYPE IS Basic;\n\nOUTPUT:  SAMPSTAT PATTERNS;\nplot: type = plot1 plot2;\n7. Check descriptive statistics and missingness patterns\nTo make sure your data has been correctly converted to the .dat file, run some descriptive statistics in both SPSS and Mplus. Because of the default methods each program uses to deal with missing data, you will probably have to do a few things to get an equivalent comparison. I ask SPSS to use listwise deletion for descriptive statistics. Then I do the same in Mplus. Take a look a the SPSS syntax file and the Mplus files that have ‘LW’ in the title for details of how to do this. Basically, it entails including something like the following code in SPSS:\n    DESCRIPTIVES VARIABLES=readk read1 mathk math1 male white other\n    /STATISTICS=MEAN STDDEV MIN MAX\n    /MISSING=LISTWISE.\nNotice the last line is a missing command, and is not available in the drop down menu. So you will have to use the syntax editor (but you should be doing that anyway!).\nFor Mplus include the following command as part of the data section of the input file:\n       LISTWISE = ON;\nYou can also compare the missingness patterns generated by SPSS and Mplus (see the ‘LW’ files) which should be the same. However, note that the orientation of patterns differs in the two programs.\nAnd that’s it! You can download all the code files for this demonstration from my github page found here. The ‘stars.sps’ and the ‘SPSSdescriptivesLW.sps’ files contain all the syntax needed to complete this tutorial.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-01-11T11:51:05-06:00",
    "input_file": {}
  },
  {
    "path": "posts/2018-12-15-fiml-regression/",
    "title": "FIML in Lavaan: Regression Analysis",
    "description": "This tutorial demonstrates how to use full information maximum likelihood (FIML) estimation to deal with missing data in a regression model using `lavaan`.",
    "author": [
      {
        "name": "William Murrah",
        "url": "https://statistical-thinking.com"
      }
    ],
    "date": "2018-12-15",
    "categories": [],
    "contents": "\nImport Data\nIn this post I use FIML to deal with missing data in a multiple regression framework. First, I import the data from a text file named ‘employee.dat’. You can download a zip file of the data from Applied Missing Data website. I also have a github page for these examples here. Remember to replace the file path in the read.table function with the path to the text file location on your computer.\n\n\nemployee <- read.table(\"data/employee.dat\")\n\n\n\nBecause the original text file does not include variable names, I name the variables in the new data frame:\n\n\nnames(employee) <-  c(\"id\", \"age\", \"tenure\", \"female\", \"wbeing\", \"jobsat\", \n                     \"jobperf\", \"turnover\", \"iq\")\n\n\n\nthen I recode all data points with the value of -99 in the original text file, which indicates a missing value, to NA, the missing data value recognized by R.\n\n\nemployee[employee == -99] <-  NA\n\n\n\nCreate Regression Model Object\nNow we are ready to create a character string containing the regression model using the lavaan model conventions. Note that b1 and b2 are labels that will be used later for the Wald test. These labels are equivalent to (b1) and (b2) after these variables in the Mplus code.\n\n\nmodel <- '\n# Regression model \njobperf ~ b1*wbeing + b2*jobsat\n\n# Variances\nwbeing ~~ wbeing\njobsat ~~ jobsat\n\n# Covariance/correlation\nwbeing ~~ jobsat\n'\n\n\n\nIn addition to the regression model, I also estimated the variances and covariances of the predictors. I did this to replicate the results of the original Mplus example. In Mplus you have to estimate the variances of all of the predictors if any of them have missing data that you would like to model. In lavaan the fixed.x=FALSE argument has the same effect (see below).\nFit the Model\nNext, I use the sem function to fit the model.\n\n\nfit <- sem(model, employee, missing='fiml', meanstructure=TRUE, \n           fixed.x=FALSE)\n\n\n\nListwise deletion is the default, so the missing=‘fiml’ argument tell lavaan to use the FIML instead. I also included the meanstructure=TRUE argument to include the means of the observed variables in the model, and the fixed.x=FALSE argument to estimate the means, variances, and covariances. Again, I do this to replicate the results of the original Mplus example.\nGenerate Output\nWe are now ready to look at the results.\n\n\nsummary(fit, fit.measures=TRUE, rsquare=TRUE, standardize=TRUE)\n\n\n\nCompared to what we learned in the last post, the only thing new to the summary function is the rsquare=TRUE argument, which, not surprisingly, results in the model R2 being included in the summary output.\nI only show the Parameter estimates section here:\nParameter estimates:\n\n  Information                                 Observed\n  Standard Errors                             Standard\n\n                   Estimate  Std.err  Z-value  P(&gt;|z|)   Std.lv  Std.all\nRegressions:\n  jobperf ~\n    wbeing   (b1)     0.476    0.055    8.665    0.000    0.476    0.447\n    jobsat   (b2)     0.027    0.060    0.444    0.657    0.027    0.025\n\nCovariances:\n  wbeing ~~\n    jobsat            0.467    0.098    4.780    0.000    0.467    0.336\n\nIntercepts:\n    jobperf           2.869    0.382    7.518    0.000    2.869    2.289\n    wbeing            6.286    0.063   99.692    0.000    6.286    5.338\n    jobsat            5.959    0.065   91.836    0.000    5.959    5.055\n\nVariances:\n    wbeing            1.387    0.108                      1.387    1.000\n    jobsat            1.390    0.109                      1.390    1.000\n    jobperf           1.243    0.087                      1.243    0.792\n\nR-Square:\n\n    jobperf           0.208\nWald Test\nIn lavaan the Wald test is called separately from the estimation function. This function will use the labels assigned in the model object above.\n\n\n# Wald test is called seperately.\nlavTestWald(fit,  constraints='b1 == 0\n                               b2 == 0')\n\n\n\nResults of Wald Test\n$stat\n[1] 95.88081\n\n$df\n[1] 2\n\n$p.value\n[1] 0\nThere you have it! Regression with FIML in R. But, what if you have variables that you are not interested in incorporating in your model, but may have information about the missingness in the variables that are in your model? I will talk about that in the next post.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-01-11T11:51:05-06:00",
    "input_file": {}
  },
  {
    "path": "posts/2018-11-14-fiml-in-lavaan-descriptive-statistics/",
    "title": "FIML in Lavaan: Descriptive Statistics",
    "description": "A new article created using the Distill format.",
    "author": [
      {
        "name": "William Murrah",
        "url": "www.statistical-thinking.com"
      }
    ],
    "date": "2018-11-14",
    "categories": [],
    "contents": "\nFIML for Missing Data in Lavaan\nFull information maximum likelihood (FIML) is a modern statistical technique for handling missing data. If you are not familiar with FIML, I would recommend the book entitled Applied Missing Data Analysis by Craig Enders. The book is both thorough and accessible, and a good place to start for those not familiar with the ins and outs of modern missing data techniques.\nThe purpose of the FIML in Lavaan series of posts and the related git repository is to take some of the examples related to FIML estimation within a regression framework from the Applied Missing Data website, and translate them into code for the R package lavaan. The code on the Applied Missing Data website in mostly for Mplus, which is quite expensive software. I hope this will give those who don’t have access to Mplus the ability to work through the examples using free and open source software.\nIn this first tutorial I start with the basics: how to get descriptive statistics using FIML. The data and Mplus code for this example can be found on the Book Examples page of the Applied Missing Data website. I also created a github repository with the data and R files with equivalent code in lavaan, which can be found here. Remember to replace the file path in the R code below with the file path to the folder in which you unzip the data files.\nYou will also want to read over the lavaan documentation and visit the very helpful lavaan website to take advantage of the tutorials there. With these resources at your disposal, you should be able to use replicate the examples in lavaan. Here, I walk through the major sections of the R code. This is the same code found in the github repository in the R file entitled FIMLdescriptivesCorrelations.R.\nHeader\nI always include a header with basic information in my code files.\n\n\n#***********************************************************************\n# section 4.14 Summary Statistics --------------------------------------\n# Author: William M. Murrah\n# Description: This code replicates the section 4.14 example on the \n#              the appliedmissingdata.com website, which generates \n#              descriptive statistics and correlations,\n# Version history ------------------------------------------------------\n# 2014.05.30: code created\n# 2014.06.01: rewrote heading\n#***********************************************************************\n# R packages used\nlibrary(lavaan)\n\n\n\nImport and prepare data\nFirst, import the data into R. MPlus uses .dat files which can only contain numbers. Variable names are not included in the .dat file, but instead are included in the Mplus .inp file. I use the read.table function to read the .dat file.\n\n\n    employee <- read.table(\"data/employee.dat\")\n\n\n\nNext, I assign names to the variables in the new data frame.\n\n\n    # Assign names to variables.\n    names(employee) <- c(\"id\", \"age\", \"tenure\", \"female\", \"wbeing\", \n                         \"jobsat\", \"jobperf\", \"turnover\", \"iq\")\n\n\n\nThe final step in preparing the data is to recode the data values -99, which are used as missing data values in the .dat file, to NA, which is the missing value indicator in R.\n\n\n    # Replace all missing values (-99) with R missing value character 'NA'.\n    employee[employee==-99] <- NA\n\n\n\nCreate Model Object\nNow that the data are ready, I create a character string with the model using the lavaan syntax. For descriptives and correlations I model the mean, variances, and covariance/correlations.\n\n\n    # Create descriptive model object\n    model <- '\n    # means\n    age      ~ 1\n    tenure   ~ 1\n    female   ~ 1\n    wbeing   ~ 1\n    jobsat   ~ 1\n    jobperf  ~ 1\n    turnover ~ 1\n    iq       ~ 1\n    \n    # variances\n    age      ~~ age\n    tenure   ~~ tenure\n    female   ~~ female\n    wbeing   ~~ wbeing\n    jobsat   ~~ jobsat\n    jobperf  ~~ jobperf\n    turnover ~~ turnover\n    iq       ~~ iq\n    \n    # covariances/correlations\n    age      ~~ tenure + female + wbeing + jobsat + jobperf + turnover + iq\n    tenure   ~~ female + wbeing + jobsat + jobperf + turnover + iq\n    female   ~~ wbeing + jobsat + jobperf + turnover + iq\n    wbeing   ~~ jobsat + jobperf + turnover + iq\n    jobsat   ~~ jobperf + turnover + iq\n    jobperf  ~~ turnover + iq\n    turnover ~~ iq\n    '\n\n\n\nFit the Model\nTo fit the model, I use the lavaan sem function. This function takes the first two argument model and data. The third argument is missing ='fiml', which tells lavaan to use FIML (the default is to use listwise deletion).\n\n\n    fit <- sem(model, employee, missing='fiml')\n\n\n\nAlternatively, you could leave the section of the model code under the # means section and use the meanstructure=TRUE argument in the fit function as follows, which give the same results:\n\n\n    fit <- sem(model, employee, missing='fiml', meanstructure=TRUE)\n\n\n\nGenerate Output\nTo print the results to the console, use the summary function.\n\n\n    summary(fit, fit.measures=TRUE, standardize=TRUE)\n\n\n\nThe fit.measures=TRUE calls fit statistics in the output. This should look familiar to those who have used Mplus.\nlavaan (0.5-16) converged normally after 141 iterations\n\n  Number of observations                           480\n\n  Number of missing patterns                         3\n\n  Estimator                                         ML\n  Minimum Function Test Statistic                0.000\n  Degrees of freedom                                 0\n  P-value (Chi-square)                           1.000\n\nModel test baseline model:\n\n  Minimum Function Test Statistic              527.884\n  Degrees of freedom                                28\n  P-value                                        0.000\n\nUser model versus baseline model:\n\n  Comparative Fit Index (CFI)                    1.000\n  Tucker-Lewis Index (TLI)                       1.000\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -6621.805\n  Loglikelihood unrestricted model (H1)      -6621.805\n\n  Number of free parameters                         44\n  Akaike (AIC)                               13331.609\n  Bayesian (BIC)                             13515.256\n  Sample-size adjusted Bayesian (BIC)        13375.604\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.000\n  90 Percent Confidence Interval          0.000  0.000\n  P-value RMSEA <= 0.05                          1.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.000\nThe standardize=TRUE argument includes columns with standardized output. the std.all column in lavaan output is the same as the STDYX section in Mplus.\nParameter estimates:\n\n  Information                                 Observed\n  Standard Errors                             Standard\n\n                   Estimate  Std.err  Z-value  P(>|z|)   Std.lv  Std.all\nCovariances:\n  age ~~\n    tenure            8.459    0.858    9.865    0.000    8.459    0.504\n    female           -0.028    0.122   -0.229    0.819   -0.028   -0.010\n    wbeing            1.148    0.334    3.433    0.001    1.148    0.182\n    jobsat            0.861    0.340    2.531    0.011    0.861    0.136\n    jobperf          -0.330    0.308   -1.072    0.284   -0.330   -0.049\n    turnover         -0.377    0.116   -3.255    0.001   -0.377   -0.150\n    iq                0.674    2.066    0.326    0.744    0.674    0.015\n  tenure ~~\n    female           -0.052    0.071   -0.736    0.462   -0.052   -0.034\n    wbeing            0.569    0.195    2.916    0.004    0.569    0.155\n    jobsat            0.565    0.200    2.822    0.005    0.565    0.154\n    jobperf           0.061    0.178    0.344    0.731    0.061    0.016\n    turnover          0.016    0.066    0.240    0.810    0.016    0.011\n    iq                0.026    1.199    0.022    0.983    0.026    0.001\n  female ~~\n    wbeing            0.067    0.031    2.156    0.031    0.067    0.115\n    jobsat            0.028    0.031    0.881    0.378    0.028    0.047\n    jobperf          -0.009    0.029   -0.323    0.747   -0.009   -0.015\n    turnover          0.001    0.011    0.114    0.909    0.001    0.005\n    iq                0.284    0.192    1.481    0.139    0.284    0.068\n  wbeing ~~\n    jobsat            0.446    0.095    4.714    0.000    0.446    0.322\n    jobperf           0.671    0.084    8.030    0.000    0.671    0.456\n    turnover         -0.141    0.030   -4.768    0.000   -0.141   -0.257\n    iq                2.876    0.530    5.430    0.000    2.876    0.291\n  jobsat ~~\n    jobperf           0.271    0.080    3.378    0.001    0.271    0.184\n    turnover         -0.129    0.030   -4.248    0.000   -0.129   -0.234\n    iq                4.074    0.566    7.195    0.000    4.074    0.411\n  jobperf ~~\n    turnover         -0.203    0.028   -7.168    0.000   -0.203   -0.346\n    iq                4.496    0.523    8.588    0.000    4.496    0.426\n  turnover ~~\n    iq               -0.706    0.182   -3.872    0.000   -0.706   -0.180\n\nIntercepts:\n    age              37.948    0.245  154.633    0.000   37.948    7.058\n    tenure           10.054    0.142   70.601    0.000   10.054    3.222\n    female            0.542    0.023   23.817    0.000    0.542    1.087\n    wbeing            6.288    0.062  100.701    0.000    6.288    5.349\n    jobsat            5.950    0.063   94.052    0.000    5.950    5.053\n    jobperf           6.021    0.057  105.262    0.000    6.021    4.805\n    turnover          0.321    0.021   15.058    0.000    0.321    0.687\n    iq              100.102    0.384  260.475    0.000  100.102   11.889\n\nVariances:\n    age              28.908    1.866                     28.908    1.000\n    tenure            9.735    0.628                      9.735    1.000\n    female            0.248    0.016                      0.248    1.000\n    wbeing            1.382    0.107                      1.382    1.000\n    jobsat            1.386    0.108                      1.386    1.000\n    jobperf           1.570    0.101                      1.570    1.000\n    turnover          0.218    0.014                      0.218    1.000\n    iq               70.892    4.576                     70.892    1.000\nRecall that correlations are standardized covariances, so correlations are found in the std.all column in the Covariances section. Also, intercepts are means, and can be interpreted as the FIML means for the variables.\nFinally, to get the missing data patterns and covariance coverage output that can be included in Mplus output use the following code:\n\n\n    # Get missing data patterns and covariance coverage similar\n    # to that found in Mplus output.\n    inspect(fit, 'patterns') \n    inspect(fit, 'coverage')\n\n\n\nwhich leads to the following output:\nMissing Data Patterns\n    age tenure female wbeing jobsat jobprf turnvr iq\n160   1      1      1      1      1      1      1  1\n160   1      1      1      1      0      1      1  1\n160   1      1      1      0      1      1      1  1\nCovariance Coverage\n\n         age   tenure female wbeing jobsat jobprf turnvr iq   \nage      1.000                                                \ntenure   1.000 1.000                                          \nfemale   1.000 1.000  1.000                                   \nwbeing   0.667 0.667  0.667  0.667                            \njobsat   0.667 0.667  0.667  0.333  0.667                     \njobperf  1.000 1.000  1.000  0.667  0.667  1.000              \nturnover 1.000 1.000  1.000  0.667  0.667  1.000  1.000       \niq       1.000 1.000  1.000  0.667  0.667  1.000  1.000  1.000\n\n\n\n",
    "preview": {},
    "last_modified": "2021-01-11T11:51:05-06:00",
    "input_file": {}
  }
]
